{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Mining Project - Stock Market Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Data Pre-Processing and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages and define datasets directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "datasets_directory = r\"C:\\Users\\Ron Michaeli\\Dropbox\\4th Year 1st Semester\\Web Mining\\Project\\Datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a set of stop words and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list = set(stopwords.words(\"english\") + list(string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the combined dataset into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_news_djia_df = pd.read_csv( \"C:\\\\Users\\\\ravedan\\\\PycharmProjects\\\\Project-Stock-Market-Prediction\\\\Data\\\\Combined_News_DJIA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to clean the text in the Reddit headlines columns (the function applies per each \"cell\" in these columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(cell_text):\n",
    "    cell_text = str(cell_text)\n",
    "    if cell_text.startswith(\"b\\\"\") or cell_text.startswith(\"b\\'\"):\n",
    "        cell_text = cell_text[1:]\n",
    "    cell_text = cell_text.replace(\"\\\"\", \"\").replace(\"\\'\", \"\")\n",
    "    tokens = nltk.word_tokenize(cell_text)\n",
    "    clean_text = \"\"\n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        if token not in stop_list and len(token) > 1:\n",
    "            clean_text += token + \" \"\n",
    "    return clean_text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the Reddit headlines columns in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_columns = combined_news_djia_df.columns[range(2, 27)]\n",
    "combined_news_djia_df[headlines_columns] = combined_news_djia_df[headlines_columns].applymap(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th># of Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  # of Samples\n",
       "0      0           924\n",
       "1      1          1065"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or c in [0, 1]:\n",
    "    samples_per_class.append([c, combined_news_djia_df[\"Label\"].value_counts()[c]])\n",
    "pd.DataFrame(samples_per_class, columns=['Class', '# of Samples'])samples_per_class = []\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can say that the data is pretty much balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top frequent words of each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "to_frame() takes at most 2 arguments (3 given)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-edbce64ef9f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mword_frequency_per_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_frequency_per_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_frequency_per_headline_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mword_frequency_per_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_frequency_per_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_frequency_per_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_frequency_per_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Word Frequency'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'j'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: to_frame() takes at most 2 arguments (3 given)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "n = 10\n",
    "for c in [0, 1]:\n",
    "    print 'Class:', c\n",
    "    word_frequency_per_class = pd.Series()\n",
    "    class_df = combined_news_djia_df.loc[combined_news_djia_df[\"Label\"] == c]\n",
    "    for headline_column in combined_news_djia_df[headlines_columns]:\n",
    "        word_frequency_per_headline_column = pd.Series(\" \".join(class_df[headline_column]).split()).value_counts()[:n]\n",
    "        word_frequency_per_class = word_frequency_per_class.append(word_frequency_per_headline_column)\n",
    "    word_frequency_per_class = word_frequency_per_class.groupby(by=word_frequency_per_class.index).sum().sort_values(ascending=False)\n",
    "    print(word_frequency_per_class.to_frame('Word Frequency'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is no apparent difference in frequent words between the two classes.\n",
    "\n",
    "We would expect that class '0' will contain more negative words such as: war, killed, etc. that may cause a negative public mood, and lead to a decrease of DJIA.\n",
    "\n",
    "It's fair to say that, in terms of frequent words, both classes are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Google Correlate & Google Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the attached report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Keras & Non-Keras Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create X, y datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_news_djia_df.drop([\"Label\", \"Date\"], axis=1)\n",
    "y = combined_news_djia_df[[\"Label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset 80-20 for Pipeline fitting and cross-validation.\n",
    "\n",
    "Why we split the dataset?\n",
    "\n",
    "a) Becuase we have enough data to afford splitting.\n",
    "\n",
    "b) To prevent overfitting.\n",
    "\n",
    "c) To use them later for the chosen model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert X_train and X_test to a list of lists (all 25 headlines per day are joined to one list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x: \" \".join(x), axis=1).tolist()\n",
    "X_test = X_test.apply(lambda x: \" \".join(x), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Keras Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = \\\n",
    "{\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'SGDClassifier': SGDClassifier(),\n",
    "    'Perceptron': Perceptron()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Pipeline and it's built-in CV to compare between the classifiers, using TF-IDF vectorizer as feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for classifier in classifiers:\n",
    "    print classifier\n",
    "    pipeline = Pipeline([('vect', TfidfVectorizer()), ('clf', classifiers[classifier])])\n",
    "    parameters = {'vect__max_df': np.arange(0.1, 1, 0.1),\n",
    "                  'clf__alpha': np.arange(0.01, 0.1, 0.01)}\n",
    "    gs_clf = GridSearchCV(pipeline, parameters, n_jobs=1, cv=5)\n",
    "    gs_clf = gs_clf.fit(X_train, y_train)\n",
    "    print 'Best params:', gs_clf.best_params_\n",
    "    print 'Mean cross-validated score:', gs_clf.best_score_\n",
    "    print ''\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that SGD Classifier presents the highest mean CV score (~54%), so this is our chosen model.\n",
    "\n",
    "Let's test the SGD Classifier accuracy using the best params and AUC evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(max_df=0.3)\n",
    "X_train_transformed = tf_idf_vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = tf_idf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "sgd_classifier = SGDClassifier(alpha=0.06)\n",
    "sgd_classifier.fit(X_train_transformed, y_train)\n",
    "prediction = sgd_classifier.predict(X_test_transformed)\n",
    "print 'AUC score:', metrics.roc_auc_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant packages for Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create LSTM-RNN model and fit it on train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = 10000\n",
    "\n",
    "#create the model\n",
    "embedding_vector_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vector_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train_transformed, y_train, validation_data=(X_test_transformed, y_test), epochs=3, batch_size=128)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param    \n",
    "=================================================================\n",
    "embedding_2 (Embedding)      (None, None, 32)          320000    \n",
    "_________________________________________________________________\n",
    "lstm_2 (LSTM)                (None, 100)               53200     \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 1)                 101       \n",
    "=================================================================\n",
    "Total params: 373,301\n",
    "Trainable params: 373,301\n",
    "Non-trainable params: 0\n",
    "_________________________________________________________________\n",
    "None\n",
    "Train on 1591 samples, validate on 398 samples\n",
    "Epoch 1/3\n",
    "1591/1591 [==============================] - 7810s 5s/step - loss: 0.6910 - acc: 0.5405 - val_loss: 0.6947 - val_acc: 0.5151\n",
    "Epoch 2/3\n",
    "1591/1591 [==============================] - 8906s 6s/step - loss: 0.6902 - acc: 0.5405 - val_loss: 0.6946 - val_acc: 0.5151\n",
    "Epoch 3/3\n",
    "1591/1591 [==============================] - 9832s 6s/step - loss: 0.6901 - acc: 0.5405 - val_loss: 0.6930 - val_acc: 0.5151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test_transformed, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 51.51%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Predict New Data Using The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to test our models on the latest actual data from Reddit and Yahoo! Finance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the PRAW package to collect the top 25 headlines in the past 14 days from Reddit.\n",
    "\n",
    "* Dow Jones data will be based on past 10 business days = 14 calendar days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reddit API credentials to be authenticated via OAuth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='iNh-qH0nZTHNUw',\n",
    "                     client_secret='AbZlGO-Hb15xmMagvOoU0EMjMgo',\n",
    "                     password='davidalush',\n",
    "                     user_agent='alusha1',\n",
    "                     username='alusha89')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all posts from Reddit\\WorldNews within the past 14 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 14\n",
    "now = int(time.time())\n",
    "two_weeks_ago = now - (60 * 60 * 24 * days)\n",
    "posts_from_past_two_weeks = list(reddit.subreddit('worldnews').submissions(two_weeks_ago, now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the posts by their scores in descending order (=hottest posts first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_from_past_two_weeks.sort(key=lambda x: x.score, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect top 25 posts per each day in the past 14 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_posts = 25\n",
    "top_25_posts_from_past_two_weeks = {}\n",
    "for post in posts_from_past_two_weeks:\n",
    "    formatted_date = datetime.datetime.fromtimestamp(post.created).strftime('%m/%d/%Y')\n",
    "    if formatted_date not in top_25_posts_from_past_two_weeks:\n",
    "        top_25_posts_from_past_two_weeks[formatted_date] = []\n",
    "    if len(top_25_posts_from_past_two_weeks[formatted_date]) < num_of_posts:\n",
    "        top_25_posts_from_past_two_weeks[formatted_date].append(post.title.encode('ascii', 'ignore'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Reddit data to DataFrame to facilitate further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_reddit_data = pd.DataFrame.from_dict(top_25_posts_from_past_two_weeks, orient='index').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process Reddit data the same way done in Question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_columns = latest_reddit_data.columns[range(0, 25)]\n",
    "latest_reddit_data[headlines_columns] = latest_reddit_data[headlines_columns].applymap(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_reddit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo! Finance Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use BeautifulSoup and urllib to crawl Yahoo! Finance and get the DJIA table of the past 10 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib2\n",
    "\n",
    "page = urllib2.urlopen(\"https://finance.yahoo.com/quote/%5EDJI/history?p=%5EDJI\")\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "latest_djia_table = pd.read_html(str(soup.find(\"table\", class_=\"W(100%) M(0)\")), header=0)[0]\n",
    "latest_djia_table = latest_djia_table.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify each day's label according to Kaggle's instructions:\n",
    "\n",
    "* \"1\" when DJIA Adj Close value rose or stayed as the same\n",
    "\n",
    "* \"0\" when DJIA Adj Close value decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_djia_table[\"Label\"] = latest_djia_table[\"Adj Close**\"] >= latest_djia_table[\"Adj Close**\"].shift(-1)\n",
    "latest_djia_table[\"Label\"] = latest_djia_table[\"Label\"].astype(int)\n",
    "latest_djia_data = latest_djia_table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is to reformat the Date column so we can join latest_reddit_data and latest_djia_data on that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_date(cell_text):\n",
    "    return datetime.datetime.strptime(cell_text, '%b %d, %Y').strftime('%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latest_djia_data[\"Date\"] = latest_djia_data[\"Date\"].apply(reformat_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_djia_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join Reddit and Yahoo! Finance tables on \"Date\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_combined_news_djia_df = pd.merge(latest_djia_data[[\"Date\", \"Label\"]], latest_reddit_data, left_on=\"Date\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_combined_news_djia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Latest Data Using Non-Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_latest = latest_combined_news_djia_df.drop([\"Label\", \"Date\"], axis=1)\n",
    "y_latest = latest_combined_news_djia_df[[\"Label\"]]\n",
    "input_data = X_latest.apply(lambda x: \" \".join(x), axis=1).tolist()\n",
    "input_data_transformed = tf_idf_vectorizer.transform(input_data)\n",
    "pred = sgd_classifier.predict(input_data_transformed)\n",
    "print 'AUC score:', metrics.roc_auc_score(y_latest, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the AUC score is lower than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Latest Data Using Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(new_X_test_transformed)\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_test_transformed = tf_idf_vectorizer.fit_transform(new_X_test)\n",
    "scores = model.evaluate(X_test_transformed, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 80.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
